# Введение в Kafka

## Что такое Kafka

Следующий текст - выдержка из https://kafka.apache.org/intro. Рекомендуется прочитать содержимое ссылки самостоятельно.

Apache Kafka - это платформа для потоковой передачи событий. 

Kafka реализует три ключевые функции:

- Публикация (запись) и подписка (чтение) потоков событий, включая непрерывный импорт/экспорт данных из внешних систем.
- Надёжное хранение событий на необходимый срок
- Обработка потоков событий в режиме реального времени либо ретроспективно.

## Необходимый софт

- **Docker+WSL2**, чтобы собирать и запускать Linux-контейнеры.
- (опционально) **.NET 7 SDK**, чтобы собирать клиентские приложения.

## Структура решения

- **KafkaProducer** - простая консольная C# утилита, которая каждые 10 секунд публикует простое сообщение, содержащее дату-время создания, в топик Kafka "time", и логирует это в stdout. 
- **KafkaConsumer** - простая консольная C# утилита, которая подписывается на топик Kafka "time", логирует каждое полученное сообщение в stdout и ждёт одну секунду, имитируя обработку сообщения.
- **Scripts** - простейшие Powershell-скрипты для демонстрации работы с Kafka.
- **compose.yaml** - файл Docker Compose, агрегирующий все необходимые контейнеры.

## Пошаговая демонстрация

1. Откройте powershell, запустите docker-compose.
    ```powershell
    cd SOLUTION_WORKIR
    docker-compose up
    ```
2. В результате шага 1 должны собраться и запуститься 4 контейнера:
    - kafka-kafka-1 - Kafka
    - kafka-ui-1 - Kafka UI
    - kafka-publisher-1 - KafkaProducer
    - kafka-consumer1-1 - первый KafkaConsumer
    - kafka-consumer2-2 - второй KafkaConsumer

   В Powershell-инстансе, из которого были запущены контейнеры, можно увидеть stdout всех контейнеров, включая publisher-а и consumer-ов:
   ```
   TODO: вставить пример логов 
   ```
3. Можно заметить, что несмотря на то, что работают два consumer-а, только один получает сообщения. Это происходит из-за того, что в Kafka после старта не создались никакие топики. Когда паблишер отправил первое сообщение в топик time, Kafka автоматически создал топик с одной партицией (эту функцию желательно отключать в продакшне). В рамках одной партиции гарантируется хронологический порядок обработки событий, и только один подписчик может получать сообщения из одной партиции. TODO: добавить шаг про добавление партиции.

## Полезные ссылки

- [Apache Kafka](https://kafka.apache.org/intro)
- [Клиент Kafka для C# от Confluent](https://docs.confluent.io/kafka-clients/dotnet/current/overview.html)
- [Хабр - Учимся жить с Kafka без Zookeeper](https://habr.com/ru/companies/otus/articles/670440/)